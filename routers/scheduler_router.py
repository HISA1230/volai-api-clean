# routers/scheduler_router.py
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime, timezone
from sqlalchemy import or_
import numpy as np
import os
import logging
import shutil  # â† æ˜‡æ ¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ã«ä½¿ç”¨

from auth.auth_jwt import get_current_user
from database.database_user import get_db
from models.models_user import UserModel, PredictionLog, ModelEval, ModelMeta
from automl.auto_trainer import AutoTrainer

router = APIRouter(prefix="/scheduler", tags=["Scheduler"])
log = logging.getLogger(__name__)

# -------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ --------
def compute_mae_for_model(db: Session, model_path: str) -> Dict[str, Any]:
    """PredictionLog ã‹ã‚‰æŒ‡å®šãƒ¢ãƒ‡ãƒ«ã® MAE ã‚’ç®—å‡º"""
    mp_norm = model_path.replace("\\", "/")
    mp_base = os.path.basename(mp_norm)

    q = (
        db.query(PredictionLog)
        .filter(PredictionLog.actual_volatility.isnot(None))
        .filter(
            or_(
                PredictionLog.model_path == mp_norm,
                PredictionLog.model_path == model_path,
                PredictionLog.model_path == model_path.replace("\\", "/"),
                PredictionLog.model_path.like(f"%/{mp_base}"),
                PredictionLog.model_path.like(f"%\\{mp_base}"),
            )
        )
    )
    rows = q.all()
    if not rows:
        return {"mae": None, "n": 0}

    abs_errors = []
    for r in rows:
        if r.abs_error is not None:
            abs_errors.append(r.abs_error)
        elif r.predicted_volatility is not None and r.actual_volatility is not None:
            abs_errors.append(abs(r.predicted_volatility - r.actual_volatility))

    if not abs_errors:
        return {"mae": None, "n": 0}
    return {"mae": float(np.mean(abs_errors)), "n": len(abs_errors)}

def list_models() -> List[str]:
    """models ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã® .pkl ã‚’åˆ—æŒ™ï¼ˆSHAPã¯é™¤å¤–ï¼‰"""
    if not os.path.exists("models"):
        return []
    paths = []
    for f in os.listdir("models"):
        if f.endswith(".pkl") and not f.endswith("_shap_values.pkl"):
            p = os.path.join("models", f)
            paths.append(p.replace("\\", "/"))
    return paths

# -------- ãƒªã‚¯/ãƒ¬ã‚¹å®šç¾© --------
class RunRequest(BaseModel):
    mae_threshold: Optional[float] = Field(default=None, description="ã“ã®å€¤ã‚’è¶…ãˆã‚‹MAEãªã‚‰å†å­¦ç¿’")
    min_new_labels: Optional[int] = Field(default=None, description="æ–°è¦ã®æ­£è§£ãƒ©ãƒ™ãƒ«ä»¶æ•°é–¾å€¤ï¼ˆã“ã®æ•°ä»¥ä¸Šãªã‚‰å†å­¦ç¿’ï¼‰")
    top_k: int = 3
    auto_promote: bool = True
    note: Optional[str] = None

class RunResult(BaseModel):
    checked_models: List[Dict[str, Any]]
    triggered: List[Dict[str, Any]]

# -------- åŸºæœ¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆæ—¢å­˜ã®ã¾ã¾ï¼‰ --------
@router.get("/health")
def health_check():
    return {"status": "ok", "time": datetime.now(timezone.utc).isoformat()}

@router.post("/eval-now")
def eval_now(
    model_path: Optional[str] = None,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """æ—¢å®šï¼ˆpinnedï¼‰ã¾ãŸã¯æŒ‡å®šãƒ¢ãƒ‡ãƒ«ã®MAEã‚’è©•ä¾¡"""
    if not model_path:
        pinned = db.query(ModelMeta).filter_by(pinned=True).first()
        if not pinned:
            raise HTTPException(status_code=400, detail="No pinned model")
        model_path = pinned.model_path
    stat = compute_mae_for_model(db, model_path)
    return {"model_path": model_path, "mae": stat["mae"], "n": stat["n"]}

@router.post("/retrain-if-needed")
def retrain_if_needed(
    model_path: Optional[str] = None,
    mae_threshold: float = 0.05,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """MAEãŒé–¾å€¤ã‚’è¶…ãˆã¦ã„ãŸã‚‰ãã®ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    if not model_path:
        pinned = db.query(ModelMeta).filter_by(pinned=True).first()
        if not pinned:
            raise HTTPException(status_code=400, detail="No pinned model")
        model_path = pinned.model_path

    stat = compute_mae_for_model(db, model_path)
    if stat["mae"] is None:
        return {"error": "No evaluation data"}
    if stat["mae"] <= mae_threshold:
        return {"status": "skipped", "mae": stat["mae"]}

    trainer = AutoTrainer(
        data_path=None,
        model_path=model_path,
        feature_cols=["rci", "atr", "vix"],
        label_col="actual_volatility",
    )
    trainer.load_data_from_db()
    trainer.filter_top_features(top_k=3)
    trainer.train_new_model()
    trainer.save_model(model_path)
    new_stat = compute_mae_for_model(db, model_path)
    return {"status": "retrained", "mae_before": stat["mae"], "mae_after": new_stat["mae"]}

@router.get("/status")
def status(
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    recs = (
        db.query(ModelEval)
        .order_by(ModelEval.ran_at.desc())
        .limit(20)
        .all()
    )
    value = [
        {
            "ran_at": r.ran_at.isoformat(),
            "model_path": r.model_path,
            "metric_mae": r.metric_mae,
            "n_samples": r.n_samples,
            "triggered_by": r.triggered_by,
            "new_model_path": r.new_model_path,
            "promoted": r.promoted,
            "note": r.note,
        }
        for r in recs
    ]
    return {"value": value, "Count": len(value)}  # äº’æ›

@router.post("/run", response_model=RunResult)
def run_scheduler(
    body: RunRequest,
    current_user: UserModel = Depends(get_current_user),
    db: Session = Depends(get_db),
):
    """ï¼ˆæ—¢å­˜ï¼‰JSONãƒœãƒ‡ã‚£å¿…é ˆã®ç·åˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©"""
    models = list_models()
    checked: List[Dict[str, Any]] = []
    triggered: List[Dict[str, Any]] = []

    # 1) ç¾çŠ¶MAEã‚’è¨ˆç®—
    mae_map: Dict[str, Dict[str, Any]] = {}
    for mp in models:
        stat = compute_mae_for_model(db, mp)
        mae_map[mp] = stat
        checked.append({"model_path": mp, "mae": stat["mae"], "n": stat["n"]})

    # 2) æ¡ä»¶ã«å¿œã˜ã¦å†å­¦ç¿’ãƒ»æ˜‡æ ¼
    for mp in models:
        stat = mae_map.get(mp, {"mae": None, "n": 0})
        reason: Optional[str] = None

        if body.mae_threshold is not None and stat["mae"] is not None and stat["mae"] > body.mae_threshold:
            reason = "threshold"
        elif body.min_new_labels is not None and stat["n"] is not None and stat["n"] >= body.min_new_labels:
            reason = "count"

        if reason is None:
            continue

        stamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        base = os.path.splitext(os.path.basename(mp))[0]
        new_model_path = f"models/{base}_auto_{stamp}.pkl"

        trainer = AutoTrainer(
            data_path=None,
            model_path=new_model_path,
            feature_cols=["rci", "atr", "vix"],
            label_col="actual_volatility",
        )
        trainer.load_data_from_db()

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if getattr(trainer, "df", None) is None or trainer.df.empty:
            eval_rec = ModelEval(
                model_path=mp,
                metric_mae=stat["mae"],
                n_samples=stat["n"],
                triggered_by=reason,
                note="no training data",
                new_model_path=None,
                promoted=False,
            )
            db.add(eval_rec)
            db.commit()
            log.warning("No training data for %s; skipped retrain.", mp)
            continue

        # å­¦ç¿’ã€œä¿å­˜
        trainer.filter_top_features(top_k=max(1, int(body.top_k or 3)))
        trainer.train_new_model()
        trainer.save_model(new_model_path)

        # è‡ªå‹•æ˜‡æ ¼ï¼ˆç°¡æ˜“ï¼‰
        promoted = False
        if body.auto_promote:
            try:
                with open("models/.default_model.txt", "w", encoding="utf-8") as f:
                    f.write(new_model_path)
                promoted = True
            except Exception as e:
                log.exception("Failed to promote new model: %s", e)
                promoted = False

        # å±¥æ­´ã¸ä¿å­˜
        eval_rec = ModelEval(
            model_path=mp,
            metric_mae=stat["mae"],
            n_samples=stat["n"],
            triggered_by=reason,
            note=body.note,
            new_model_path=new_model_path,
            promoted=promoted,
        )
        db.add(eval_rec)
        db.commit()

        # â˜… æ˜‡æ ¼æ™‚ã®SHAPå†è¨ˆç®—ï¼ˆä»»æ„ï¼‰
        if promoted:
            try:
                from utils.shap_ops import recompute_shap_files
                recompute_shap_files(new_model_path, feature_cols=["rci", "atr", "vix"])
            except Exception as e:
                log.exception("SHAP recompute failed for %s: %s", new_model_path, e)

        triggered.append(
            {
                "base_model": mp,
                "reason": reason,
                "old_mae": stat["mae"],
                "old_n": stat["n"],
                "new_model_path": new_model_path,
                "promoted": promoted,
            }
        )

    # 3) é€šçŸ¥ï¼ˆpromoted ã®ã¨ãã ã‘é€ã‚‹ï¼‰
    if triggered:
        try:
            from utils.notifier import notify_all
            for ev in triggered:
                if not ev.get("promoted"):
                    continue
                title = "ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ã‚¤ãƒ™ãƒ³ãƒˆ"
                payload = {
                    "base_model": ev.get("base_model"),
                    "reason": ev.get("reason"),
                    "old_mae": ev.get("old_mae"),
                    "old_n": ev.get("old_n"),
                    "new_model_path": ev.get("new_model_path"),
                    "promoted": ev.get("promoted"),
                    "note": None,
                }
                notify_all(title, payload)
        except Exception as e:
            log.exception("notify_all failed: %s", e)

    return RunResult(checked_models=checked, triggered=triggered)

# -------- è¿½åŠ ï¼šãƒœãƒ‡ã‚£ä¸è¦ã®ç°¡æ˜“3ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ --------

@router.post("/retrain/dryrun")
def retrain_dryrun(
    top_k: int = Query(3, ge=1, le=50, description="ç›¸é–¢ä¸Šä½ã®æ¡ç”¨æ•°"),
    current_user: UserModel = Depends(get_current_user),
):
    """ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿â†’ç‰¹å¾´é‡é¸åˆ¥ã¾ã§ï¼ˆãƒœãƒ‡ã‚£ä¸è¦ï¼‰"""
    trainer = AutoTrainer()
    df = trainer.load_data_from_db()
    feats = trainer.filter_top_features(top_k=top_k)
    return {"rows": len(df), "selected_features": feats, "label": trainer.label_col}

@router.post("/retrain/run")
def retrain_run(
    top_k: int = Query(3, ge=1, le=50, description="ç›¸é–¢ä¸Šä½ã®æ¡ç”¨æ•°"),
    model_path: Optional[str] = Query(None, description="ä¿å­˜å…ˆãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã€‚æœªæŒ‡å®šãªã‚‰ stage ã«ä¿å­˜"),
    current_user: UserModel = Depends(get_current_user),
):
    """æœ¬ç•ªï¼šå­¦ç¿’â†’ä¿å­˜â†’SHAPå‡ºåŠ›ï¼ˆãƒœãƒ‡ã‚£ä¸è¦ï¼‰"""
    save_to = model_path or "models/vol_model_stage.pkl"
    trainer = AutoTrainer(model_path=save_to)
    df = trainer.load_data_from_db()
    feats = trainer.filter_top_features(top_k=top_k)
    trainer.train_new_model()
    trainer.save_model(save_to)

    shap_csv = save_to.replace(".pkl", "_shap_summary.csv")
    return {
        "saved_model": save_to,
        "shap_summary": shap_csv,
        "selected_features": feats,
        "rows": len(df),
    }

@router.post("/retrain/promote")
def retrain_promote(
    current_user: UserModel = Depends(get_current_user),
):
    """æ˜‡æ ¼ï¼šstage â†’ æ—¢å®šãƒ¢ãƒ‡ãƒ«ï¼ˆSHAPã‚‚åŒæ™‚ã‚³ãƒ”ãƒ¼ï¼‰"""
    stage = "models/vol_model_stage.pkl"
    dest = "models/vol_model.pkl"
    if not os.path.exists(stage):
        raise HTTPException(status_code=404, detail="staged model not found")

    os.makedirs(os.path.dirname(dest), exist_ok=True)
    shutil.copy2(stage, dest)

    for ext in ["_shap_summary.csv", "_shap_values.pkl"]:
        src = stage.replace(".pkl", ext)
        if os.path.exists(src):
            shutil.copy2(src, dest.replace(".pkl", ext))

    return {
        "default_model": dest,
        "shap_summary": dest.replace(".pkl", "_shap_summary.csv"),
    }